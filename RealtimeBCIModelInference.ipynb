{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Purpose: We aim to make use of real time streamed data \n","- get stream of incoming data on lsl\n","- collect data for a second\n","- run inference on the data of that second\n","- continuously give output, collect new data"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Imports\n","from pylsl import StreamInlet, resolve_stream\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{},"source":["# Initialize and load trained model"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Init NN model\n","class NeuralNetworkClassificationModel(nn.Module):\n","    def __init__(self,input_dim,output_dim):\n","        super(NeuralNetworkClassificationModel,self).__init__()\n","        self.input_layer    = nn.Linear(input_dim,128)\n","        self.hidden_layer1  = nn.Linear(128,64)\n","        self.output_layer   = nn.Linear(64,output_dim)\n","        self.relu = nn.ReLU()\n","    \n","    \n","    def forward(self,x):\n","        out =  self.relu(self.input_layer(x))\n","        out =  self.relu(self.hidden_layer1(out))\n","        out =  self.output_layer(out)\n","        return out\n","\n","# Load model\n","input_dim  = 16\n","output_dim = 2\n","model = NeuralNetworkClassificationModel(input_dim,output_dim)\n","model.load_state_dict(torch.load(\"Saved models/toTestIfRealtimeWorks.pth\"))"]},{"cell_type":"markdown","metadata":{},"source":["# Define functions for getting observed data, and get inference on data"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# get data func\n","def getData(inlet):\n","    items = []\n","    t_end = time.time() + 0.5\n","\n","    while time.time() < t_end:\n","        # get a new sample (you can also omit the timestamp part if you're not\n","        # interested in it)\n","        sample, timestamp = inlet.pull_sample()\n","        items.append(sample)\n","    return items\n","\n","# get inference func (longest time it took on pracc data was 0.003 sec. that means i can have shorter data collection \n","# )\n","def getInference(samples):\n","    tensor = torch.tensor(samples)\n","    predictions = []\n","    final = []\n","    with torch.no_grad():\n","        predictions = model(tensor)\n","\n","    predictions = predictions.numpy()\n","\n","    for i in range(len(predictions)):\n","            final.append(np.argmax(predictions[i]))\n","    final = np.array(final)    \n","    print(\"the most occuring predicted class in the samples:\", np.argmax(np.bincount(final)), \"with percentage:\", np.bincount(final)[np.argmax(np.bincount(final))] / len(final), \"out of:\", len(final))\n","    mostOccuringClass = np.argmax(np.bincount(final))\n","\n","    return final, mostOccuringClass"]},{"cell_type":"markdown","metadata":{},"source":["# Run functions to get data and inference"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["looking for an EEG stream...\n","the most occuring predicted class in the samples: 1 with percentage: 0.9090909090909091 out of: 66\n","the most occuring predicted class in the samples: 1 with percentage: 0.8769230769230769 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8923076923076924 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8923076923076924 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8769230769230769 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.9230769230769231 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8769230769230769 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.9142857142857143 out of: 70\n","the most occuring predicted class in the samples: 1 with percentage: 0.8923076923076924 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8923076923076924 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8615384615384616 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8923076923076924 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8923076923076924 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8923076923076924 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8923076923076924 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.9230769230769231 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.9076923076923077 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8769230769230769 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.9076923076923077 out of: 65\n","the most occuring predicted class in the samples: 1 with percentage: 0.8615384615384616 out of: 65\n","total time taken 10.44843053817749\n"]}],"source":["# first resolve an EEG stream on the lab network\n","print(\"looking for an EEG stream...\")\n","streams = resolve_stream('type', 'EEG')\n","\n","# create a new inlet to read from the stream\n","inlet = StreamInlet(streams[0])\n","\n","t_endOuter = time.time() + 10\n","starterTime = time.time()\n","\n","while time.time() < t_endOuter:\n","    samples = getData(inlet)\n","    predictions = getInference(samples)\n","\n","finisherTime = time.time()\n","print(\"total time taken\", finisherTime - starterTime)\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNPP5DGXplOzqLAip/MCruK","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"vscode":{"interpreter":{"hash":"1c1ac5f0940aa62225d61e7f7716c5cb40912f37c1e0976efc76c58205cce6bf"}}},"nbformat":4,"nbformat_minor":0}
